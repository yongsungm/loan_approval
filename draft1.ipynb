{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b259ce0d-26ab-4c25-9b8a-34a2dd52ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 04:11:18,591] A new study created in memory with name: no-name-80b3b182-7aad-42bb-8910-96b6ed2ad136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training Loss: 0.2299, Validation Loss: 0.2092\n",
      "Best model weights saved.\n",
      "Epoch [2/50], Training Loss: 0.1994, Validation Loss: 0.1951\n",
      "Best model weights saved.\n",
      "Epoch [3/50], Training Loss: 0.1969, Validation Loss: 0.1995\n",
      "Epoch [4/50], Training Loss: 0.1911, Validation Loss: 0.1987\n",
      "Epoch [5/50], Training Loss: 0.1881, Validation Loss: 0.1924\n",
      "Best model weights saved.\n",
      "Epoch [6/50], Training Loss: 0.1898, Validation Loss: 0.2002\n",
      "Epoch [7/50], Training Loss: 0.1922, Validation Loss: 0.1986\n",
      "Epoch [8/50], Training Loss: 0.1871, Validation Loss: 0.1979\n",
      "Epoch [9/50], Training Loss: 0.1848, Validation Loss: 0.1919\n",
      "Best model weights saved.\n",
      "Epoch [10/50], Training Loss: 0.1842, Validation Loss: 0.1967\n",
      "Epoch [11/50], Training Loss: 0.1859, Validation Loss: 0.1934\n",
      "Epoch [12/50], Training Loss: 0.1839, Validation Loss: 0.1934\n",
      "Epoch [13/50], Training Loss: 0.1840, Validation Loss: 0.1910\n",
      "Best model weights saved.\n",
      "Epoch [14/50], Training Loss: 0.1848, Validation Loss: 0.1964\n",
      "Epoch [15/50], Training Loss: 0.1807, Validation Loss: 0.1954\n",
      "Epoch [16/50], Training Loss: 0.1805, Validation Loss: 0.2074\n",
      "Epoch [17/50], Training Loss: 0.1868, Validation Loss: 0.1974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 04:11:44,882] Trial 0 finished with value: 0.9410026145276799 and parameters: {'hidden_size1': 85, 'hidden_size2': 53, 'dropout_rate': 0.11575027750757352, 'learning_rate': 0.03245367661353664, 'batch_size': 51}. Best is trial 0 with value: 0.9410026145276799.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Training Loss: 0.1815, Validation Loss: 0.1930\n",
      "Early stopping triggered.\n",
      "Training stopped early.\n",
      "Best model weights saved to best_model_trial_0.pth\n",
      "Epoch [1/50], Training Loss: 0.3072, Validation Loss: 0.2727\n",
      "Best model weights saved.\n",
      "Epoch [2/50], Training Loss: 0.2146, Validation Loss: 0.2073\n",
      "Best model weights saved.\n",
      "Epoch [3/50], Training Loss: 0.1975, Validation Loss: 0.1920\n",
      "Best model weights saved.\n",
      "Epoch [4/50], Training Loss: 0.1951, Validation Loss: 0.1957\n",
      "Epoch [5/50], Training Loss: 0.1926, Validation Loss: 0.1971\n",
      "Epoch [6/50], Training Loss: 0.1898, Validation Loss: 0.1894\n",
      "Best model weights saved.\n",
      "Epoch [7/50], Training Loss: 0.1924, Validation Loss: 0.1948\n",
      "Epoch [8/50], Training Loss: 0.1895, Validation Loss: 0.1923\n",
      "Epoch [9/50], Training Loss: 0.1896, Validation Loss: 0.1962\n",
      "Epoch [10/50], Training Loss: 0.1898, Validation Loss: 0.1917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 04:12:00,054] Trial 1 finished with value: 0.9438444924406048 and parameters: {'hidden_size1': 68, 'hidden_size2': 26, 'dropout_rate': 0.3167053193207532, 'learning_rate': 0.058590104996889894, 'batch_size': 51}. Best is trial 1 with value: 0.9438444924406048.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Training Loss: 0.1881, Validation Loss: 0.1958\n",
      "Early stopping triggered.\n",
      "Training stopped early.\n",
      "Best model weights saved to best_model_trial_1.pth\n",
      "Epoch [1/50], Training Loss: 0.2357, Validation Loss: 0.1966\n",
      "Best model weights saved.\n",
      "Epoch [2/50], Training Loss: 0.1872, Validation Loss: 0.1936\n",
      "Best model weights saved.\n",
      "Epoch [3/50], Training Loss: 0.1827, Validation Loss: 0.1922\n",
      "Best model weights saved.\n",
      "Epoch [4/50], Training Loss: 0.1799, Validation Loss: 0.1939\n",
      "Epoch [5/50], Training Loss: 0.1780, Validation Loss: 0.1874\n",
      "Best model weights saved.\n",
      "Epoch [6/50], Training Loss: 0.1761, Validation Loss: 0.1879\n",
      "Epoch [7/50], Training Loss: 0.1754, Validation Loss: 0.1868\n",
      "Best model weights saved.\n",
      "Epoch [8/50], Training Loss: 0.1734, Validation Loss: 0.1864\n",
      "Best model weights saved.\n",
      "Epoch [9/50], Training Loss: 0.1724, Validation Loss: 0.1852\n",
      "Best model weights saved.\n",
      "Epoch [10/50], Training Loss: 0.1710, Validation Loss: 0.1873\n",
      "Epoch [11/50], Training Loss: 0.1697, Validation Loss: 0.1850\n",
      "Best model weights saved.\n",
      "Epoch [12/50], Training Loss: 0.1686, Validation Loss: 0.1861\n",
      "Epoch [13/50], Training Loss: 0.1667, Validation Loss: 0.1882\n",
      "Epoch [14/50], Training Loss: 0.1665, Validation Loss: 0.1884\n",
      "Epoch [15/50], Training Loss: 0.1657, Validation Loss: 0.1842\n",
      "Best model weights saved.\n",
      "Epoch [16/50], Training Loss: 0.1644, Validation Loss: 0.1855\n",
      "Epoch [17/50], Training Loss: 0.1637, Validation Loss: 0.1882\n",
      "Epoch [18/50], Training Loss: 0.1627, Validation Loss: 0.1850\n",
      "Epoch [19/50], Training Loss: 0.1619, Validation Loss: 0.1855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 04:12:55,129] Trial 2 finished with value: 0.9460043196544277 and parameters: {'hidden_size1': 78, 'hidden_size2': 45, 'dropout_rate': 0.367835810890057, 'learning_rate': 0.0018573713305110227, 'batch_size': 23}. Best is trial 2 with value: 0.9460043196544277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Training Loss: 0.1610, Validation Loss: 0.1866\n",
      "Early stopping triggered.\n",
      "Training stopped early.\n",
      "Best model weights saved to best_model_trial_2.pth\n",
      "Epoch [1/50], Training Loss: 0.3112, Validation Loss: 0.2353\n",
      "Best model weights saved.\n",
      "Epoch [2/50], Training Loss: 0.2213, Validation Loss: 0.2123\n",
      "Best model weights saved.\n",
      "Epoch [3/50], Training Loss: 0.2026, Validation Loss: 0.2025\n",
      "Best model weights saved.\n",
      "Epoch [4/50], Training Loss: 0.1934, Validation Loss: 0.1983\n",
      "Best model weights saved.\n",
      "Epoch [5/50], Training Loss: 0.1887, Validation Loss: 0.1947\n",
      "Best model weights saved.\n",
      "Epoch [6/50], Training Loss: 0.1856, Validation Loss: 0.1924\n",
      "Best model weights saved.\n",
      "Epoch [7/50], Training Loss: 0.1839, Validation Loss: 0.1914\n",
      "Best model weights saved.\n",
      "Epoch [8/50], Training Loss: 0.1822, Validation Loss: 0.1913\n",
      "Best model weights saved.\n",
      "Epoch [9/50], Training Loss: 0.1812, Validation Loss: 0.1913\n",
      "Best model weights saved.\n",
      "Epoch [10/50], Training Loss: 0.1801, Validation Loss: 0.1903\n",
      "Best model weights saved.\n",
      "Epoch [11/50], Training Loss: 0.1791, Validation Loss: 0.1901\n",
      "Best model weights saved.\n",
      "Epoch [12/50], Training Loss: 0.1784, Validation Loss: 0.1909\n",
      "Epoch [13/50], Training Loss: 0.1776, Validation Loss: 0.1903\n",
      "Epoch [14/50], Training Loss: 0.1771, Validation Loss: 0.1911\n",
      "Epoch [15/50], Training Loss: 0.1765, Validation Loss: 0.1900\n",
      "Best model weights saved.\n",
      "Epoch [16/50], Training Loss: 0.1758, Validation Loss: 0.1909\n",
      "Epoch [17/50], Training Loss: 0.1753, Validation Loss: 0.1898\n",
      "Best model weights saved.\n",
      "Epoch [18/50], Training Loss: 0.1747, Validation Loss: 0.1914\n",
      "Epoch [19/50], Training Loss: 0.1744, Validation Loss: 0.1892\n",
      "Best model weights saved.\n",
      "Epoch [20/50], Training Loss: 0.1741, Validation Loss: 0.1884\n",
      "Best model weights saved.\n",
      "Epoch [21/50], Training Loss: 0.1735, Validation Loss: 0.1893\n",
      "Epoch [22/50], Training Loss: 0.1732, Validation Loss: 0.1896\n",
      "Epoch [23/50], Training Loss: 0.1730, Validation Loss: 0.1881\n",
      "Best model weights saved.\n",
      "Epoch [24/50], Training Loss: 0.1725, Validation Loss: 0.1893\n",
      "Epoch [25/50], Training Loss: 0.1723, Validation Loss: 0.1886\n",
      "Epoch [26/50], Training Loss: 0.1715, Validation Loss: 0.1903\n",
      "Epoch [27/50], Training Loss: 0.1712, Validation Loss: 0.1887\n",
      "Epoch [28/50], Training Loss: 0.1710, Validation Loss: 0.1884\n",
      "Early stopping triggered.\n",
      "Training stopped early.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 04:14:26,584] Trial 3 finished with value: 0.9425940661589178 and parameters: {'hidden_size1': 72, 'hidden_size2': 22, 'dropout_rate': 0.3743961454979392, 'learning_rate': 0.00023916543792409985, 'batch_size': 19}. Best is trial 2 with value: 0.9460043196544277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights saved to best_model_trial_3.pth\n",
      "Epoch [1/50], Training Loss: 0.2339, Validation Loss: 0.2144\n",
      "Best model weights saved.\n",
      "Epoch [2/50], Training Loss: 0.1914, Validation Loss: 0.2109\n",
      "Best model weights saved.\n",
      "Epoch [3/50], Training Loss: 0.1884, Validation Loss: 0.1895\n",
      "Best model weights saved.\n",
      "Epoch [4/50], Training Loss: 0.1845, Validation Loss: 0.1913\n",
      "Epoch [5/50], Training Loss: 0.1833, Validation Loss: 0.1881\n",
      "Best model weights saved.\n",
      "Epoch [6/50], Training Loss: 0.1816, Validation Loss: 0.1957\n",
      "Epoch [7/50], Training Loss: 0.1809, Validation Loss: 0.1924\n",
      "Epoch [8/50], Training Loss: 0.1790, Validation Loss: 0.1950\n",
      "Epoch [9/50], Training Loss: 0.1779, Validation Loss: 0.1907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 04:14:38,809] Trial 4 finished with value: 0.9417983403432989 and parameters: {'hidden_size1': 49, 'hidden_size2': 39, 'dropout_rate': 0.2536293032028729, 'learning_rate': 0.017264053227669874, 'batch_size': 64}. Best is trial 2 with value: 0.9460043196544277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Training Loss: 0.1771, Validation Loss: 0.1898\n",
      "Early stopping triggered.\n",
      "Training stopped early.\n",
      "Best model weights saved to best_model_trial_4.pth\n",
      "Epoch [1/50], Training Loss: 0.3269, Validation Loss: 0.2389\n",
      "Best model weights saved.\n",
      "Epoch [2/50], Training Loss: 0.2211, Validation Loss: 0.2107\n",
      "Best model weights saved.\n",
      "Epoch [3/50], Training Loss: 0.1986, Validation Loss: 0.2002\n",
      "Best model weights saved.\n",
      "Epoch [4/50], Training Loss: 0.1895, Validation Loss: 0.1949\n",
      "Best model weights saved.\n",
      "Epoch [5/50], Training Loss: 0.1852, Validation Loss: 0.1926\n",
      "Best model weights saved.\n",
      "Epoch [6/50], Training Loss: 0.1830, Validation Loss: 0.1913\n",
      "Best model weights saved.\n",
      "Epoch [7/50], Training Loss: 0.1818, Validation Loss: 0.1909\n",
      "Best model weights saved.\n",
      "Epoch [8/50], Training Loss: 0.1808, Validation Loss: 0.1901\n",
      "Best model weights saved.\n",
      "Epoch [9/50], Training Loss: 0.1790, Validation Loss: 0.1911\n",
      "Epoch [10/50], Training Loss: 0.1782, Validation Loss: 0.1899\n",
      "Best model weights saved.\n",
      "Epoch [11/50], Training Loss: 0.1770, Validation Loss: 0.1908\n",
      "Epoch [12/50], Training Loss: 0.1768, Validation Loss: 0.1910\n",
      "Epoch [13/50], Training Loss: 0.1757, Validation Loss: 0.1908\n",
      "Epoch [14/50], Training Loss: 0.1754, Validation Loss: 0.1915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 04:15:00,432] Trial 5 finished with value: 0.9421393656928498 and parameters: {'hidden_size1': 68, 'hidden_size2': 30, 'dropout_rate': 0.48338386851063697, 'learning_rate': 0.0004319376049765508, 'batch_size': 50}. Best is trial 2 with value: 0.9460043196544277.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Training Loss: 0.1755, Validation Loss: 0.1912\n",
      "Early stopping triggered.\n",
      "Training stopped early.\n",
      "Best model weights saved to best_model_trial_5.pth\n",
      "Best hyperparameters:  {'hidden_size1': 78, 'hidden_size2': 45, 'dropout_rate': 0.367835810890057, 'learning_rate': 0.0018573713305110227, 'batch_size': 23}\n",
      "Best accuracy:  0.9460043196544277\n",
      "\n",
      "Hyperparameter Tuning Results:\n",
      "   Trial  Hidden Size 1  Hidden Size 2  Dropout Rate  Learning Rate  \\\n",
      "0      0             85             53      0.115750       0.032454   \n",
      "1      1             68             26      0.316705       0.058590   \n",
      "2      2             78             45      0.367836       0.001857   \n",
      "3      3             72             22      0.374396       0.000239   \n",
      "4      4             49             39      0.253629       0.017264   \n",
      "5      5             68             30      0.483384       0.000432   \n",
      "\n",
      "   Batch Size  Accuracy  \n",
      "0          51  0.941003  \n",
      "1          51  0.943844  \n",
      "2          23  0.946004  \n",
      "3          19  0.942594  \n",
      "4          64  0.941798  \n",
      "5          50  0.942139  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import optuna\n",
    "\n",
    "class LoanDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "class LoanPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.categorical_features = [\n",
    "            'person_home_ownership', \n",
    "            'loan_intent', \n",
    "            'loan_grade', \n",
    "            'cb_person_default_on_file'\n",
    "        ]\n",
    "        \n",
    "        self.numerical_features = [\n",
    "            'person_age', \n",
    "            'person_income', \n",
    "            'person_emp_length', \n",
    "            'loan_amnt', \n",
    "            'loan_int_rate', \n",
    "            'loan_percent_income', \n",
    "            'cb_person_cred_hist_length'\n",
    "        ]\n",
    "        \n",
    "        self.preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), self.numerical_features),\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore'), self.categorical_features)\n",
    "            ])\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.preprocessor.fit_transform(X)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.preprocessor.transform(X)\n",
    "\n",
    "class LoanNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, dropout_rate):\n",
    "        super(LoanNeuralNetwork, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size1, hidden_size2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score:  # Assuming lower score is better (e.g., validation loss)\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "\n",
    "def validate_model(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs.view(-1), labels)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=50, patience=5):\n",
    "    model.train()\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    best_val_loss = float('inf')  # Initialize best validation loss\n",
    "    best_model_weights = None  # To store the best model weights\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs.view(-1), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        val_loss = validate_model(model, val_loader, criterion, device)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {avg_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # Check early stopping\n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Training stopped early.\")\n",
    "            break\n",
    "\n",
    "        # Save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_weights = model.state_dict()  # Save the model weights\n",
    "            print(\"Best model weights saved.\")\n",
    "\n",
    "    return best_model_weights  # Return the best model weights\n",
    "\n",
    "def objective(trial):\n",
    "    hidden_size1 = trial.suggest_int('hidden_size1', 32, 128)\n",
    "    hidden_size2 = trial.suggest_int('hidden_size2', 16, 64)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 64)\n",
    "\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = LoanNeuralNetwork(input_size=X_train.shape[1], \n",
    "                               hidden_size1=hidden_size1, \n",
    "                               hidden_size2=hidden_size2, \n",
    "                               dropout_rate=dropout_rate).to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model and get the best model weights\n",
    "    best_model_weights = train_model(model, train_loader, val_loader, criterion, optimizer, device, epochs=50)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            predicted = (outputs.view(-1) > 0.5).float()  # Ensure outputs are flattened\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # Save the best model weights to a file\n",
    "    model_save_path = f\"best_model_trial_{trial.number}.pth\"\n",
    "    torch.save(best_model_weights, model_save_path)\n",
    "    print(f\"Best model weights saved to {model_save_path}\")\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "X = data.drop('loan_status', axis=1)\n",
    "y = data['loan_status']\n",
    "\n",
    "preprocessor = LoanPreprocessor()\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_processed, y, test_size=0.3, random_state=420\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=69\n",
    ")\n",
    "\n",
    "train_dataset = LoanDataset(X_train, y_train.values)\n",
    "val_dataset = LoanDataset(X_val, y_val.values)\n",
    "test_dataset = LoanDataset(X_test, y_test.values)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=6)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best accuracy: \", study.best_value)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = []\n",
    "for trial in study.trials:\n",
    "    results.append({\n",
    "        'Trial': trial.number,\n",
    "        'Hidden Size 1': trial.params['hidden_size1'],\n",
    "        'Hidden Size 2': trial.params['hidden_size2'],\n",
    "        'Dropout Rate': trial.params['dropout_rate'],\n",
    "        'Learning Rate': trial.params['learning_rate'],\n",
    "        'Batch Size': trial.params['batch_size'],\n",
    "        'Accuracy': trial.value\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nHyperparameter Tuning Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results_df.to_csv('hyperparameter_tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2510bfb5-2fd0-4e77-ab70-a7a20e97534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model weights\n",
    "best_model_weights = torch.load(f\"best_model_trial_{study.best_trial.number}.pth\")\n",
    "\n",
    "preprocessor = LoanPreprocessor()\n",
    "\n",
    "# Load the best model\n",
    "best_model = LoanNeuralNetwork(\n",
    "    input_size=submission_data.shape[1], \n",
    "    hidden_size1=study.best_params['hidden_size1'], \n",
    "    hidden_size2=study.best_params['hidden_size2'], \n",
    "    dropout_rate=study.best_params['dropout_rate']\n",
    ").to(device)\n",
    "\n",
    "# Load the best model weights\n",
    "best_model.load_state_dict(best_model_weights)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b2f4b4b-f3bc-42b0-813e-e5cefe53052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1822\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "test_loss = validate_model(best_model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3171caa9-e975-4634-8d31-0af84f68037d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9475\n"
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = best_model(features)\n",
    "            predicted = (outputs.view(-1) > 0.5).float()  # Ensure outputs are flattened\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = correct / total\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "157504ee-bac9-4809-8bde-54e645b97943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "raw_submission_data = pd.read_csv('./data/test.csv')\n",
    "submission_data = preprocessor.fit_transform(raw_submission_data)\n",
    "\n",
    "# Create the test dataset\n",
    "submission_dataset = LoanDataset(submission_data, np.zeros(len(submission_data)))  # Placeholder for labels\n",
    "\n",
    "# Create the test data loader\n",
    "submission_loader = DataLoader(submission_dataset, batch_size=study.best_params['batch_size'], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1e7b297-0ab6-434f-b13b-074183783e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions saved to test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = []\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    for features, _ in submission_loader:  # Ignore labels in test data\n",
    "        features = features.to(device)\n",
    "        outputs = best_model(features)\n",
    "        predicted = (outputs.view(-1) > 0.5).float()  # Ensure outputs are flattened\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Create a DataFrame to store the predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'id': raw_submission_data['id'],  # Include the original 'id' column\n",
    "    'loan_status': predictions\n",
    "})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('test_predictions.csv', index=False)\n",
    "\n",
    "print(\"Test predictions saved to test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a893e-d1c8-48da-a007-cda196139ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
