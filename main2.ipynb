{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1d605a-c398-4c6f-af7e-3e5cfe7f1435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aaf334d-c43b-425c-8bb3-0b372a5a9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i classes.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea92d3d-4c04-4c92-b056-513124d11da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual hyperparameters\n",
    "epochs = 50\n",
    "patience = 7\n",
    "num_trials = 1 # For hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b1f4ac-4e25-464d-b65b-15dd3d0bc8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and split the data\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "X = data.drop('loan_status', axis=1)\n",
    "y = data['loan_status']\n",
    "\n",
    "preprocessor = LoanPreprocessor()\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_processed, y, test_size=0.3, random_state=420\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=69\n",
    ")\n",
    "\n",
    "train_dataset = LoanDataset(X_train, y_train.values)\n",
    "val_dataset = LoanDataset(X_val, y_val.values)\n",
    "test_dataset = LoanDataset(X_test, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6abc46be-1de8-4c7b-bdf2-eaa5e2311112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8a2737-b76e-4e10-b09a-bb4d9eeba3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 05:09:37,693] A new study created in memory with name: no-name-57ec2030-4620-4a5c-afed-3ee278f5c55e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training Loss: 0.4464, Validation Loss: 0.3070\n",
      "Best model weights saved.\n",
      "Epoch [2/50], Training Loss: 0.2739, Validation Loss: 0.2511\n",
      "Best model weights saved.\n",
      "Epoch [3/50], Training Loss: 0.2441, Validation Loss: 0.2378\n",
      "Best model weights saved.\n",
      "Epoch [4/50], Training Loss: 0.2345, Validation Loss: 0.2324\n",
      "Best model weights saved.\n",
      "Epoch [5/50], Training Loss: 0.2291, Validation Loss: 0.2282\n",
      "Best model weights saved.\n",
      "Epoch [6/50], Training Loss: 0.2246, Validation Loss: 0.2253\n",
      "Best model weights saved.\n",
      "Epoch [7/50], Training Loss: 0.2205, Validation Loss: 0.2216\n",
      "Best model weights saved.\n",
      "Epoch [8/50], Training Loss: 0.2165, Validation Loss: 0.2187\n",
      "Best model weights saved.\n",
      "Epoch [9/50], Training Loss: 0.2127, Validation Loss: 0.2163\n",
      "Best model weights saved.\n",
      "Epoch [10/50], Training Loss: 0.2094, Validation Loss: 0.2127\n",
      "Best model weights saved.\n",
      "Epoch [11/50], Training Loss: 0.2062, Validation Loss: 0.2103\n",
      "Best model weights saved.\n",
      "Epoch [12/50], Training Loss: 0.2034, Validation Loss: 0.2082\n",
      "Best model weights saved.\n",
      "Epoch [13/50], Training Loss: 0.2009, Validation Loss: 0.2062\n",
      "Best model weights saved.\n",
      "Epoch [14/50], Training Loss: 0.1987, Validation Loss: 0.2043\n",
      "Best model weights saved.\n",
      "Epoch [15/50], Training Loss: 0.1967, Validation Loss: 0.2028\n",
      "Best model weights saved.\n",
      "Epoch [16/50], Training Loss: 0.1949, Validation Loss: 0.2010\n",
      "Best model weights saved.\n",
      "Epoch [17/50], Training Loss: 0.1934, Validation Loss: 0.1998\n",
      "Best model weights saved.\n",
      "Epoch [18/50], Training Loss: 0.1920, Validation Loss: 0.1986\n",
      "Best model weights saved.\n",
      "Epoch [19/50], Training Loss: 0.1908, Validation Loss: 0.1983\n",
      "Best model weights saved.\n",
      "Epoch [20/50], Training Loss: 0.1898, Validation Loss: 0.1972\n",
      "Best model weights saved.\n",
      "Epoch [21/50], Training Loss: 0.1889, Validation Loss: 0.1963\n",
      "Best model weights saved.\n",
      "Epoch [22/50], Training Loss: 0.1880, Validation Loss: 0.1956\n",
      "Best model weights saved.\n",
      "Epoch [23/50], Training Loss: 0.1874, Validation Loss: 0.1951\n",
      "Best model weights saved.\n",
      "Epoch [24/50], Training Loss: 0.1867, Validation Loss: 0.1945\n",
      "Best model weights saved.\n",
      "Epoch [25/50], Training Loss: 0.1861, Validation Loss: 0.1939\n",
      "Best model weights saved.\n",
      "Epoch [26/50], Training Loss: 0.1856, Validation Loss: 0.1935\n",
      "Best model weights saved.\n",
      "Epoch [27/50], Training Loss: 0.1850, Validation Loss: 0.1933\n",
      "Best model weights saved.\n",
      "Epoch [28/50], Training Loss: 0.1847, Validation Loss: 0.1927\n",
      "Best model weights saved.\n",
      "Epoch [29/50], Training Loss: 0.1842, Validation Loss: 0.1927\n",
      "Best model weights saved.\n",
      "Epoch [30/50], Training Loss: 0.1838, Validation Loss: 0.1921\n",
      "Best model weights saved.\n",
      "Epoch [31/50], Training Loss: 0.1835, Validation Loss: 0.1920\n",
      "Best model weights saved.\n",
      "Epoch [32/50], Training Loss: 0.1830, Validation Loss: 0.1917\n",
      "Best model weights saved.\n",
      "Epoch [33/50], Training Loss: 0.1827, Validation Loss: 0.1917\n",
      "Epoch [34/50], Training Loss: 0.1824, Validation Loss: 0.1912\n",
      "Best model weights saved.\n",
      "Epoch [35/50], Training Loss: 0.1822, Validation Loss: 0.1913\n",
      "Epoch [36/50], Training Loss: 0.1819, Validation Loss: 0.1912\n",
      "Best model weights saved.\n",
      "Epoch [37/50], Training Loss: 0.1816, Validation Loss: 0.1907\n",
      "Best model weights saved.\n",
      "Epoch [38/50], Training Loss: 0.1813, Validation Loss: 0.1906\n",
      "Best model weights saved.\n",
      "Epoch [39/50], Training Loss: 0.1811, Validation Loss: 0.1908\n",
      "Epoch [40/50], Training Loss: 0.1808, Validation Loss: 0.1904\n",
      "Best model weights saved.\n",
      "Epoch [41/50], Training Loss: 0.1806, Validation Loss: 0.1904\n",
      "Epoch [42/50], Training Loss: 0.1803, Validation Loss: 0.1902\n",
      "Best model weights saved.\n",
      "Epoch [43/50], Training Loss: 0.1802, Validation Loss: 0.1901\n",
      "Best model weights saved.\n",
      "Epoch [44/50], Training Loss: 0.1799, Validation Loss: 0.1898\n",
      "Best model weights saved.\n",
      "Epoch [45/50], Training Loss: 0.1798, Validation Loss: 0.1900\n",
      "Epoch [46/50], Training Loss: 0.1795, Validation Loss: 0.1895\n",
      "Best model weights saved.\n",
      "Epoch [47/50], Training Loss: 0.1794, Validation Loss: 0.1893\n",
      "Best model weights saved.\n",
      "Epoch [48/50], Training Loss: 0.1791, Validation Loss: 0.1906\n",
      "Epoch [49/50], Training Loss: 0.1790, Validation Loss: 0.1901\n",
      "Epoch [50/50], Training Loss: 0.1788, Validation Loss: 0.1893\n",
      "Best model weights saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-20 05:11:42,738] Trial 0 finished with value: 0.9420256905763328 and parameters: {'hidden_size1': 43, 'hidden_size2': 59, 'dropout_rate': 0.23474574438861484, 'learning_rate': 5.2383623894552675e-05, 'batch_size': 26}. Best is trial 0 with value: 0.9420256905763328.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model weights saved to best_model_trial_0.pth\n",
      "Best hyperparameters:  {'hidden_size1': 43, 'hidden_size2': 59, 'dropout_rate': 0.23474574438861484, 'learning_rate': 5.2383623894552675e-05, 'batch_size': 26}\n",
      "Best accuracy:  0.9420256905763328\n",
      "\n",
      "Hyperparameter Tuning Results:\n",
      "   Trial  Hidden Size 1  Hidden Size 2  Dropout Rate  Learning Rate  \\\n",
      "0      0             43             59      0.234746       0.000052   \n",
      "\n",
      "   Batch Size  Accuracy  \n",
      "0          26  0.942026  \n"
     ]
    }
   ],
   "source": [
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=num_trials)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best accuracy: \", study.best_value)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = []\n",
    "for trial in study.trials:\n",
    "    results.append({\n",
    "        'Trial': trial.number,\n",
    "        'Hidden Size 1': trial.params['hidden_size1'],\n",
    "        'Hidden Size 2': trial.params['hidden_size2'],\n",
    "        'Dropout Rate': trial.params['dropout_rate'],\n",
    "        'Learning Rate': trial.params['learning_rate'],\n",
    "        'Batch Size': trial.params['batch_size'],\n",
    "        'Accuracy': trial.value\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "print(\"\\nHyperparameter Tuning Results:\")\n",
    "print(results_df)\n",
    "\n",
    "# Optionally, save the results to a CSV file\n",
    "results_df.to_csv('hyperparameter_tuning_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d38ee862-f10e-4969-9ab0-284e5de07b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model weights\n",
    "best_model_weights = torch.load(f\"best_model_trial_{study.best_trial.number}.pth\")\n",
    "\n",
    "preprocessor = LoanPreprocessor()\n",
    "\n",
    "# Load the best model\n",
    "best_model = LoanNeuralNetwork(\n",
    "    input_size=X_processed.shape[1], \n",
    "    hidden_size1=study.best_params['hidden_size1'], \n",
    "    hidden_size2=study.best_params['hidden_size2'], \n",
    "    dropout_rate=study.best_params['dropout_rate']\n",
    ").to(device)\n",
    "\n",
    "# Load the best model weights\n",
    "best_model.load_state_dict(best_model_weights)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aa3c9ef-892a-4276-b640-0fa742722609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1840\n",
      "Test accuracy: 0.9421\n"
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "test_loss = validate_model(best_model, test_loader, criterion, device)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = best_model(features)\n",
    "            predicted = (outputs.view(-1) > 0.5).float()  # Ensure outputs are flattened\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = correct / total\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0018c045-c1f1-4fef-b81c-50abf6340788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Training Loss: 0.4119\n",
      "Best model weights saved.\n",
      "Epoch [2/5], Training Loss: 0.2679\n",
      "Best model weights saved.\n",
      "Epoch [3/5], Training Loss: 0.2476\n",
      "Best model weights saved.\n",
      "Epoch [4/5], Training Loss: 0.2386\n",
      "Best model weights saved.\n",
      "Epoch [5/5], Training Loss: 0.2333\n",
      "Best model weights saved.\n",
      "Best model weights saved to final_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Train on all data with best hyperparameters\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "X = data.drop('loan_status', axis=1)\n",
    "y = data['loan_status']\n",
    "\n",
    "preprocessor = LoanPreprocessor()\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "final_dataset = LoanDataset(X_processed, y.values)\n",
    "\n",
    "# Train the final model\n",
    "final_model = LoanNeuralNetwork(\n",
    "    input_size=X_processed.shape[1], \n",
    "    hidden_size1=study.best_params['hidden_size1'], \n",
    "    hidden_size2=study.best_params['hidden_size2'], \n",
    "    dropout_rate=study.best_params['dropout_rate']\n",
    ").to(device)\n",
    "\n",
    "final_loader = DataLoader(final_dataset, batch_size=study.best_params['batch_size'], shuffle=True)\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=study.best_params['learning_rate'])\n",
    "\n",
    "final_model.train()\n",
    "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
    "best_loss = float('inf')\n",
    "best_model_weights = None  # To store the best model weights\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for features, labels in final_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(features)\n",
    "        loss = criterion(outputs.view(-1), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(final_loader)\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {avg_loss:.4f}')\n",
    "\n",
    "    # Check early stopping\n",
    "    early_stopping(avg_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Training stopped early.\")\n",
    "        break\n",
    "\n",
    "    # Save the best model\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        best_model_weights = final_model.state_dict()  # Save the model weights\n",
    "        print(\"Best model weights saved.\")\n",
    "\n",
    "# Save the best model weights to a file\n",
    "final_model_save_path = f\"final_model.pth\"\n",
    "torch.save(best_model_weights, final_model_save_path)\n",
    "print(f\"Best model weights saved to {final_model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46ea1b2f-1888-4119-a436-93cf25c5d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data for submission\n",
    "raw_submission_data = pd.read_csv('./data/test.csv')\n",
    "submission_data = preprocessor.fit_transform(raw_submission_data)\n",
    "\n",
    "# Create the test dataset\n",
    "submission_dataset = LoanDataset(submission_data, np.zeros(len(submission_data)))  # Placeholder for labels\n",
    "\n",
    "# Create the test data loader\n",
    "submission_loader = DataLoader(submission_dataset, batch_size=study.best_params['batch_size'], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bda6626f-64a8-431e-944e-192dff61384d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions saved to test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = []\n",
    "final_model.eval()\n",
    "with torch.no_grad():\n",
    "    for features, _ in submission_loader:  # Ignore labels in test data\n",
    "        features = features.to(device)\n",
    "        outputs = final_model(features)\n",
    "        predicted = (outputs.view(-1) > 0.5).float()  # Ensure outputs are flattened\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Create a DataFrame to store the predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'id': raw_submission_data['id'],  # Include the original 'id' column\n",
    "    'loan_status': predictions\n",
    "})\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df.to_csv('test_predictions.csv', index=False)\n",
    "\n",
    "print(\"Test predictions saved to test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20932537-1b81-4596-bc5f-2a52632c0c51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
